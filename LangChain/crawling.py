import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
from urllib.parse import urljoin

# ê¸°ë³¸ ì„¤ì •
base_url = "https://www.yes24.com"
data = []
headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# í¬ë¡¤ë§ ì‹¤í–‰
for i in range(1, 5):
    url = f"https://www.yes24.com/Product/Category/NewProduct?pageNumber={i}"
    print(f"ğŸ“„ [í˜ì´ì§€ {i}] í¬ë¡¤ë§ ì‹œì‘]")

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"âŒ [í˜ì´ì§€ {i}] ìš”ì²­ ì‹¤íŒ¨: {e}")
        continue

    soup = BeautifulSoup(response.text, "html.parser")
    books = soup.select(".item_info")

    for book_index, book in enumerate(books, start=1):
        print(f"ğŸ” [í˜ì´ì§€ {i} - ì±… {book_index}] ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        category_element = book.select_one(".gd_res")
        if not category_element or "[ë„ì„œ]" not in category_element.text:
            print(f"   â© [í˜ì´ì§€ {i} - ì±… {book_index}] ë„ì„œê°€ ì•„ë‹˜, ê±´ë„ˆëœ€")
            continue

        title_element = book.select_one("a.gd_name")
        if not title_element:
            print(f"   âš ï¸ [í˜ì´ì§€ {i} - ì±… {book_index}] ì œëª© ì—†ìŒ, ê±´ë„ˆëœ€")
            continue

        title = title_element.text.strip()
        href = title_element["href"]
        if href.startswith("https"):
            print(f"   â© [í˜ì´ì§€ {i} - ì±… {book_index}] ì ˆëŒ€ URL, ê±´ë„ˆëœ€: {href}")
            continue

        detail_url = urljoin(base_url, href)
        author_element = book.select_one(
            "div.info_row.info_pubGrp > span.info_auth > a:not(.moreAuthArea a)"
        )
        author = author_element.text.strip() if author_element else "ì €ì ì—†ìŒ"
        publisher_element = book.select_one(
            "div.info_row.info_pubGrp > span:nth-of-type(2)"
        )
        publisher = (
            publisher_element.text.strip() if publisher_element else "ì¶œíŒì‚¬ ì—†ìŒ"
        )
        pub_date_element = book.select_one(
            "div.info_row.info_pubGrp > span:nth-of-type(3)"
        )
        pub_date = pub_date_element.text.strip() if pub_date_element else "ì¶œíŒì¼ ì—†ìŒ"

        description = "ì„¤ëª… ì—†ìŒ"
        genres = "ì¥ë¥´ ì—†ìŒ"
        if detail_url:
            try:
                detail_response = requests.get(detail_url, headers=headers, timeout=10)
                detail_response.raise_for_status()
                detail_soup = BeautifulSoup(detail_response.text, "html.parser")

                # ì±… ì„¤ëª…
                detail_description = detail_soup.select_one("textarea.txtContentText")
                description = (
                    detail_description.text.strip()
                    if detail_description
                    else "ì„¤ëª… ì—†ìŒ"
                )

                # ì¥ë¥´ ë°ì´í„° ì¶”ì¶œ (ì˜¬ë°”ë¥¸ yesAlertLi ì„ íƒ)
                genre_section = detail_soup.select_one(
                    "dl.yesAlertDl ul.yesAlertLi"
                )  # ì •í™•í•œ ë¶€ëª¨ ìš”ì†Œ ì„ íƒ
                if genre_section:
                    genre_list = genre_section.select_one("li")  # ì²« ë²ˆì§¸ li ì„ íƒ
                    if genre_list:
                        genre_elements = genre_list.select(
                            "a"
                        )  # ì²« ë²ˆì§¸ li ë‚´ë¶€ì˜ a íƒœê·¸ ê°€ì ¸ì˜¤ê¸°
                        genres = (
                            ", ".join([g.text.strip() for g in genre_elements])
                            if genre_elements
                            else "ì¥ë¥´ ì—†ìŒ"
                        )
                    else:
                        genres = "ì¥ë¥´ ì—†ìŒ"
                else:
                    genres = "ì¥ë¥´ ì—†ìŒ"
            except requests.exceptions.RequestException as e:
                print(f"   âš ï¸ [í˜ì´ì§€ {i} - ì±… {book_index}] ìƒì„¸ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")

        print(f"âœ… [í˜ì´ì§€ {i} - ì±… {book_index}] ìˆ˜ì§‘ ì™„ë£Œ: {title} ({author})")
        data.append([title, author, publisher, pub_date, genres, description])

    time.sleep(random.uniform(1, 3))

# ê²°ê³¼ ì €ì¥
df = pd.DataFrame(
    data, columns=["title", "author", "publisher", "pub_date", "genres", "description"]
)
df.to_csv("data/result_final_with_genres_test.csv", index=False, encoding="utf-8-sig")
